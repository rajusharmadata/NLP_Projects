{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd41f99c-ad3d-44d1-9760-26b915d871fc",
   "metadata": {},
   "source": [
    "# NLP Text Preprocessing Project\n",
    "\n",
    "This project shows basic Natural Language Processing (NLP) steps to clean and process text data, such as tokenization, removing punctuation, removing stopwords, and stemming using Python and NLTK.\n",
    "\n",
    "The project helps prepare text data for tasks like text classification and sentiment analysis.\n",
    "- Author : Raju Kumar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62367034-12fb-4978-813f-531342d13dce",
   "metadata": {},
   "source": [
    "### Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954bff96-29d4-4862-b10d-829dddf925f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# NLP Project - Setup\n",
    "# ===============================\n",
    "\n",
    "# Install packages (run once)\n",
    "# !pip install nltk\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d457ecf-15d3-4877-adb8-1be37e72cab8",
   "metadata": {},
   "source": [
    "### Input Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae2ac4e-670d-47d0-b0e8-23e09f43d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Input Text\n",
    "# ===============================\n",
    "\n",
    "text = \"\"\"\n",
    "Natural language processing is fun to learn.\n",
    "It helps computers to understand human language!\n",
    "Let's explore tokenization today.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d41b52d-6be9-4278-9cf9-582bc7803106",
   "metadata": {},
   "source": [
    "### Convert Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed74a413-028e-4bdb-bc90-39c3681d44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase Text:\n",
      " \n",
      "natural language processing is fun to learn.\n",
      "it helps computers to understand human language!\n",
      "let's explore tokenization today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Text Normalization\n",
    "# ===============================\n",
    "\n",
    "# Lowercase conversion improves consistency\n",
    "lower_text = text.lower()\n",
    "\n",
    "print(\"Lowercase Text:\\n\", lower_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2329d4-ef75-4f37-bf87-3cf1ea4dec0e",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c434906-a42c-4bfe-94af-bfbbc25f3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "1. \n",
      "natural language processing is fun to learn.\n",
      "2. it helps computers to understand human language!\n",
      "3. let's explore tokenization today.\n",
      "Total Sentences: 3\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Sentence Tokenization\n",
    "# ===============================\n",
    "\n",
    "sentences = sent_tokenize(lower_text)\n",
    "\n",
    "print(\"Sentences:\")\n",
    "for i, s in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {s}\")\n",
    "\n",
    "print(\"Total Sentences:\", len(sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6a3b8-2802-46ed-95a7-4be828b3580d",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df1ecd7-6415-494f-a4d8-ec6fd0d13360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words:\n",
      "['natural', 'language', 'processing', 'is', 'fun', 'to', 'learn', '.', 'it', 'helps', 'computers', 'to', 'understand', 'human', 'language', '!', 'let', \"'s\", 'explore', 'tokenization', 'today', '.']\n",
      "Total Words: 22\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Word Tokenization\n",
    "# ===============================\n",
    "\n",
    "words = word_tokenize(lower_text)\n",
    "\n",
    "print(\"Tokenized Words:\")\n",
    "print(words)\n",
    "print(\"Total Words:\", len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de38de9-f5ba-4adc-b889-b4f8d9eff543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentences 1 :  natural languge processing is fun to learn it helps computers to understand human languge !\n",
      "Token : ['natural', 'languge', 'processing', 'is', 'fun', 'to', 'learn', 'it', 'helps', 'computers', 'to', 'understand', 'human', 'languge', '!']\n",
      "\n",
      " Sentences 2 : let's expolore tokenoization today\n",
      "Token : ['let', \"'s\", 'expolore', 'tokenoization', 'today']\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(sentences,1):\n",
    "      print(f\"\\n Sentences {i} : {s}\")\n",
    "      print(\"Token :\",word_tokenize(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810140c-ef30-4b7f-b605-3a9415ad96b6",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c117907b-779d-46ff-81fe-b67d9b2ebd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Removing Punctuation:\n",
      "['natural', 'language', 'processing', 'is', 'fun', 'to', 'learn', 'it', 'helps', 'computers', 'to', 'understand', 'human', 'language', 'let', \"'s\", 'explore', 'tokenization', 'today']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Remove Punctuation\n",
    "# ===============================\n",
    "\n",
    "clean_words = [\n",
    "    word for word in words\n",
    "    if word not in string.punctuation\n",
    "]\n",
    "\n",
    "print(\"After Removing Punctuation:\")\n",
    "print(clean_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d87b01af-33fd-4bc6-8e74-8b3e68b81da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Oringinal Words  :  ['natural', 'languge', 'processing', 'is', 'fun', 'to', 'learn', 'it', 'helps', 'computers', 'to', 'understand', 'human', 'languge', '!', 'let', \"'s\", 'expolore', 'tokenoization', 'today'] 20\n",
      "\n",
      " After Removing punctuation :  ['natural', 'languge', 'processing', 'is', 'fun', 'to', 'learn', 'it', 'helps', 'computers', 'to', 'understand', 'human', 'languge', 'let', \"'s\", 'expolore', 'tokenoization', 'today'] 19\n"
     ]
    }
   ],
   "source": [
    "clean_words = []\n",
    "for i in Words:\n",
    "    if i not in string.punctuation:\n",
    "        clean_words.append(i)\n",
    "\n",
    "print(\"\\n Oringinal Words  : \" , Words ,len(Words))\n",
    "print(\"\\n After Removing punctuation : \", clean_words , len(clean_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277e73c-0b7c-4997-8a76-9d6d714d3e2d",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd2360c-70a2-481e-8331-574a0f04e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal:\n",
      "['natural', 'language', 'processing', 'fun', 'learn', 'helps', 'computers', 'understand', 'human', 'language', 'let', \"'s\", 'explore', 'tokenization', 'today']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Stop Word Removal\n",
    "# ===============================\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "filtered_words = [\n",
    "    word for word in clean_words\n",
    "    if word not in stop_words\n",
    "]\n",
    "\n",
    "print(\"After Stopword Removal:\")\n",
    "print(filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed3c06-3f08-441d-b9ad-85e1ce64aad0",
   "metadata": {},
   "source": [
    "### Stemming Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f1c05a-7444-4893-9ebf-7357370810a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words:\n",
      "['natur', 'languag', 'process', 'fun', 'learn', 'help', 'comput', 'understand', 'human', 'languag', 'let', \"'s\", 'explor', 'token', 'today']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Stemming\n",
    "# ===============================\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_words = [\n",
    "    stemmer.stem(word)\n",
    "    for word in filtered_words\n",
    "]\n",
    "\n",
    "print(\"Stemmed Words:\")\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17fa155-4ddb-431c-a723-0f823154731b",
   "metadata": {},
   "source": [
    "### Full Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31c74d4-758b-4936-9a56-298afe86225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# NLP Pipeline Function\n",
    "# ===============================\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Full NLP preprocessing pipeline.\n",
    "    Returns processed tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    words = [w for w in words if w not in string.punctuation]\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79ebe23-3896-4aa7-b8f4-0588e3af58ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'fun', 'learn', 'help', 'comput', 'understand', 'human', 'languag', 'let', \"'s\", 'explor', 'token', 'today']\n"
     ]
    }
   ],
   "source": [
    "result = preprocess_text(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26feac-abf5-41c8-9958-3d12cdd4b277",
   "metadata": {},
   "source": [
    "##  Perfoming operation on second text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c2fb39-b13e-4139-99c5-c6f74244e34c",
   "metadata": {},
   "source": [
    "### Input Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed9da0bd-0d12-49c2-b35a-8d170ecd6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"India, officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area; \n",
    "the most populous country since 2023; and, since its independence in 1947, the world's most populous democracy. Bounded by the Indian \n",
    "Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, \n",
    "it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. \n",
    "In the Indian Ocean, India is near Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Myanmar, \n",
    "Thailand, and Indonesia.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138e6fb-4247-4aa3-9465-a3328b4c683c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e071a599-b99e-4063-90df-3e37c83ad0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case text : india, officially the republic of india, is a country in south asia. it is the seventh-largest country by area; \n",
      "the most populous country since 2023; and, since its independence in 1947, the world's most populous democracy. bounded by the indian \n",
      "ocean on the south, the arabian sea on the southwest, and the bay of bengal on the southeast, \n",
      "it shares land borders with pakistan to the west; china, nepal, and bhutan to the north; and bangladesh and myanmar to the east. \n",
      "in the indian ocean, india is near sri lanka and the maldives; its andaman and nicobar islands share a maritime border with myanmar, \n",
      "thailand, and indonesia.\n"
     ]
    }
   ],
   "source": [
    "l_text2 = text2.lower()\n",
    "\n",
    "print(\"Lower case text :\",l_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81670f37-96b5-427f-a8fd-e3a3b8652b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Sentence Tokenize : \n",
      " ['india, officially the republic of india, is a country in south asia.', \"it is the seventh-largest country by area; \\nthe most populous country since 2023; and, since its independence in 1947, the world's most populous democracy.\", 'bounded by the indian \\nocean on the south, the arabian sea on the southwest, and the bay of bengal on the southeast, \\nit shares land borders with pakistan to the west; china, nepal, and bhutan to the north; and bangladesh and myanmar to the east.', 'in the indian ocean, india is near sri lanka and the maldives; its andaman and nicobar islands share a maritime border with myanmar, \\nthailand, and indonesia.'] Total Sentences are  \n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "sentences2 = sent_tokenize(l_text2)\n",
    "print(\"After Sentence Tokenize : \\n\",sentences2,\"Total Sentences are \",\"\\n\",len(sentences2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a042036-ea55-4599-9303-1ae81d5a2f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentences 1 : india, officially the republic of india, is a country in south asia.\n",
      "Token : ['india', ',', 'officially', 'the', 'republic', 'of', 'india', ',', 'is', 'a', 'country', 'in', 'south', 'asia', '.']\n",
      "\n",
      " Sentences 2 : it is the seventh-largest country by area; \n",
      "the most populous country since 2023; and, since its independence in 1947, the world's most populous democracy.\n",
      "Token : ['it', 'is', 'the', 'seventh-largest', 'country', 'by', 'area', ';', 'the', 'most', 'populous', 'country', 'since', '2023', ';', 'and', ',', 'since', 'its', 'independence', 'in', '1947', ',', 'the', 'world', \"'s\", 'most', 'populous', 'democracy', '.']\n",
      "\n",
      " Sentences 3 : bounded by the indian \n",
      "ocean on the south, the arabian sea on the southwest, and the bay of bengal on the southeast, \n",
      "it shares land borders with pakistan to the west; china, nepal, and bhutan to the north; and bangladesh and myanmar to the east.\n",
      "Token : ['bounded', 'by', 'the', 'indian', 'ocean', 'on', 'the', 'south', ',', 'the', 'arabian', 'sea', 'on', 'the', 'southwest', ',', 'and', 'the', 'bay', 'of', 'bengal', 'on', 'the', 'southeast', ',', 'it', 'shares', 'land', 'borders', 'with', 'pakistan', 'to', 'the', 'west', ';', 'china', ',', 'nepal', ',', 'and', 'bhutan', 'to', 'the', 'north', ';', 'and', 'bangladesh', 'and', 'myanmar', 'to', 'the', 'east', '.']\n",
      "\n",
      " Sentences 4 : in the indian ocean, india is near sri lanka and the maldives; its andaman and nicobar islands share a maritime border with myanmar, \n",
      "thailand, and indonesia.\n",
      "Token : ['in', 'the', 'indian', 'ocean', ',', 'india', 'is', 'near', 'sri', 'lanka', 'and', 'the', 'maldives', ';', 'its', 'andaman', 'and', 'nicobar', 'islands', 'share', 'a', 'maritime', 'border', 'with', 'myanmar', ',', 'thailand', ',', 'and', 'indonesia', '.']\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(sentences2,1):\n",
    "      print(f\"\\n Sentences {i} : {s}\")\n",
    "      print(\"Token :\",word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fe9437e-7172-418f-9116-61a9a63987df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Word Tokenize : \n",
      " ['natural', 'languge', 'processing', 'is', 'fun', 'to', 'learn', 'it', 'helps', 'computers', 'to', 'understand', 'human', 'languge', '!', 'let', \"'s\", 'expolore', 'tokenoization', 'today'] Total Words are  \n",
      " 20\n"
     ]
    }
   ],
   "source": [
    "Words2 = word_tokenize(l_text2)\n",
    "print(\"After Word Tokenize : \\n\",Words,\"Total Words are \",\"\\n\",len(Words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db1dda15-d6b0-438c-9f7e-84d9fd70a8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Oringinal Words  :  ['india', ',', 'officially', 'the', 'republic', 'of', 'india', ',', 'is', 'a', 'country', 'in', 'south', 'asia', '.', 'it', 'is', 'the', 'seventh-largest', 'country', 'by', 'area', ';', 'the', 'most', 'populous', 'country', 'since', '2023', ';', 'and', ',', 'since', 'its', 'independence', 'in', '1947', ',', 'the', 'world', \"'s\", 'most', 'populous', 'democracy', '.', 'bounded', 'by', 'the', 'indian', 'ocean', 'on', 'the', 'south', ',', 'the', 'arabian', 'sea', 'on', 'the', 'southwest', ',', 'and', 'the', 'bay', 'of', 'bengal', 'on', 'the', 'southeast', ',', 'it', 'shares', 'land', 'borders', 'with', 'pakistan', 'to', 'the', 'west', ';', 'china', ',', 'nepal', ',', 'and', 'bhutan', 'to', 'the', 'north', ';', 'and', 'bangladesh', 'and', 'myanmar', 'to', 'the', 'east', '.', 'in', 'the', 'indian', 'ocean', ',', 'india', 'is', 'near', 'sri', 'lanka', 'and', 'the', 'maldives', ';', 'its', 'andaman', 'and', 'nicobar', 'islands', 'share', 'a', 'maritime', 'border', 'with', 'myanmar', ',', 'thailand', ',', 'and', 'indonesia', '.'] 129\n",
      "\n",
      " After Removing punctuation :  ['india', 'officially', 'the', 'republic', 'of', 'india', 'is', 'a', 'country', 'in', 'south', 'asia', 'it', 'is', 'the', 'seventh-largest', 'country', 'by', 'area', 'the', 'most', 'populous', 'country', 'since', '2023', 'and', 'since', 'its', 'independence', 'in', '1947', 'the', 'world', \"'s\", 'most', 'populous', 'democracy', 'bounded', 'by', 'the', 'indian', 'ocean', 'on', 'the', 'south', 'the', 'arabian', 'sea', 'on', 'the', 'southwest', 'and', 'the', 'bay', 'of', 'bengal', 'on', 'the', 'southeast', 'it', 'shares', 'land', 'borders', 'with', 'pakistan', 'to', 'the', 'west', 'china', 'nepal', 'and', 'bhutan', 'to', 'the', 'north', 'and', 'bangladesh', 'and', 'myanmar', 'to', 'the', 'east', 'in', 'the', 'indian', 'ocean', 'india', 'is', 'near', 'sri', 'lanka', 'and', 'the', 'maldives', 'its', 'andaman', 'and', 'nicobar', 'islands', 'share', 'a', 'maritime', 'border', 'with', 'myanmar', 'thailand', 'and', 'indonesia'] 108\n"
     ]
    }
   ],
   "source": [
    "clean_words2 = []\n",
    "for i in Words2:\n",
    "    if i not in string.punctuation:\n",
    "        clean_words2.append(i)\n",
    "\n",
    "print(\"\\n Oringinal Words  : \" , Words2 ,len(Words2))\n",
    "print(\"\\n After Removing punctuation : \", clean_words2 , len(clean_words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0c7531c-207d-4311-9e35-8a5a67f70070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " 'officially',\n",
       " 'the',\n",
       " 'republic',\n",
       " 'of',\n",
       " 'india',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'in',\n",
       " 'south',\n",
       " 'asia',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'by',\n",
       " 'area',\n",
       " 'the',\n",
       " 'most',\n",
       " 'populous',\n",
       " 'country',\n",
       " 'since',\n",
       " '2023',\n",
       " 'and',\n",
       " 'since',\n",
       " 'its',\n",
       " 'independence',\n",
       " 'in',\n",
       " '1947',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'most',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'bounded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'indian',\n",
       " 'ocean',\n",
       " 'on',\n",
       " 'the',\n",
       " 'south',\n",
       " 'the',\n",
       " 'arabian',\n",
       " 'sea',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southwest',\n",
       " 'and',\n",
       " 'the',\n",
       " 'bay',\n",
       " 'of',\n",
       " 'bengal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southeast',\n",
       " 'it',\n",
       " 'shares',\n",
       " 'land',\n",
       " 'borders',\n",
       " 'with',\n",
       " 'pakistan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'west',\n",
       " 'china',\n",
       " 'nepal',\n",
       " 'and',\n",
       " 'bhutan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'north',\n",
       " 'and',\n",
       " 'bangladesh',\n",
       " 'and',\n",
       " 'myanmar',\n",
       " 'to',\n",
       " 'the',\n",
       " 'east',\n",
       " 'in',\n",
       " 'the',\n",
       " 'indian',\n",
       " 'ocean',\n",
       " 'india',\n",
       " 'is',\n",
       " 'near',\n",
       " 'sri',\n",
       " 'lanka',\n",
       " 'and',\n",
       " 'the',\n",
       " 'maldives',\n",
       " 'its',\n",
       " 'andaman',\n",
       " 'and',\n",
       " 'nicobar',\n",
       " 'islands',\n",
       " 'share',\n",
       " 'a',\n",
       " 'maritime',\n",
       " 'border',\n",
       " 'with',\n",
       " 'myanmar',\n",
       " 'thailand',\n",
       " 'and',\n",
       " 'indonesia']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "476c306a-c0a2-4630-b5ee-761b6c4e86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27c8b7f9-5d93-4bb9-baef-fefb76bffaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing punctuation stop words :  ['india', 'officially', 'republic', 'india', 'country', 'south', 'asia', 'seventh-largest', 'country', 'area', 'populous', 'country', 'since', '2023', 'since', 'independence', '1947', 'world', \"'s\", 'populous', 'democracy', 'bounded', 'indian', 'ocean', 'south', 'arabian', 'sea', 'southwest', 'bay', 'bengal', 'southeast', 'shares', 'land', 'borders', 'pakistan', 'west', 'china', 'nepal', 'bhutan', 'north', 'bangladesh', 'myanmar', 'east', 'indian', 'ocean', 'india', 'near', 'sri', 'lanka', 'maldives', 'andaman', 'nicobar', 'islands', 'share', 'maritime', 'border', 'myanmar', 'thailand', 'indonesia']\n"
     ]
    }
   ],
   "source": [
    "filtered_words = []\n",
    "for i in clean_words2:\n",
    "    if i not in stop_words:\n",
    "        filtered_words.append(i)\n",
    "print(\"After removing punctuation stop words : \",filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fea697-f8e8-42fd-be3d-8b8771c60de5",
   "metadata": {},
   "source": [
    "### Stemming in NLP\n",
    "Stemming chops off parts of a word like (ing,ed,s) to get it's stem(root).\n",
    "It does not guarantee a real dictionary word - just common base form.\n",
    "\n",
    "Eg:\n",
    "- Running-----Run\n",
    "- Runs------- Run\n",
    "- Easily --------- Easili\n",
    "- Studies----------Studi\n",
    "\n",
    "* Notice how \"easily--> easili and \"Studies\" are not valid english words -- that's normal in stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79dabca6-a5e1-46ff-af8a-75d3bb25b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running <-----------------------------> run\n",
      "Runs <-----------------------------> run\n",
      "Change <-----------------------------> chang\n",
      "Studies <-----------------------------> studi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "word = [\"Running \", \"Runs\", \"Change\", \"Studies\"]\n",
    "\n",
    "for i in word:\n",
    "    # Strip any potential leading/trailing whitespace before stemming\n",
    "    processed_word = i.strip()\n",
    "    stemmed_word = stemmer.stem(processed_word)\n",
    "    print(f\"{processed_word} <-----------------------------> {stemmed_word}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca414c70-a3ab-474c-b68a-d06f91fa134d",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "More accurate then stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47064b3e-fb5b-4d95-8286-da037ecce517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rajus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rajus\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\") #--> WordNet is a large dictionary of english word with meaning and alternate words\n",
    "nltk.download(\"omw-1.4\") #-->updated english data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e286c3f-6211-4b3e-ba4a-d80c14284d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  <--------------> Running \n",
      "Runs <--------------> Runs\n",
      "Change <--------------> Change\n",
      "Studies <--------------> Studies\n",
      "mice <--------------> mouse\n"
     ]
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "W = [\"Running \", \"Runs\", \"Change\" , \"Studies\" ,\"mice\"]\n",
    "for i in W : \n",
    "    print(i , \"<-------------->\" ,lem.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbc832-0b6e-47a9-a12d-ed98b5fbec7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
